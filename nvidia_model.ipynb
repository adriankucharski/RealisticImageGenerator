{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Program Files\\Python\\lib\\site-packages\\transformers\\models\\segformer\\feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "e:\\Program Files\\Python\\lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "from skimage import io, transform, color\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from typing import List\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_csv(path: str = 'data/ADE20K/included_classes.csv', sep: str = ';'):\n",
    "    csv = pd.read_csv(path, sep=sep)\n",
    "    classes = {}\n",
    "    for index, (name, inc) in enumerate(zip(csv['Name'], csv['Include'])):\n",
    "        if inc:\n",
    "            classes[name] = index\n",
    "    return classes    \n",
    "    \n",
    "def clear_dataset():\n",
    "    classes = parse_csv()\n",
    "    stats = {key: 0 for key in classes.keys()}\n",
    "    has_classes = []\n",
    "\n",
    "    pixel_sums = 0\n",
    "    for pimage in tqdm(glob('data/ADE20K/annotations/*.png')):\n",
    "        im = io.imread(pimage, as_gray=True)\n",
    "        flag = False\n",
    "        for (val, key) in zip(classes.values(), classes.keys()):\n",
    "            sums = np.sum(im == val)\n",
    "            if sums > 0:\n",
    "                flag = True\n",
    "                stats[key] += sums\n",
    "                pixel_sums += im.shape[0] * im.shape[1]\n",
    "        if flag:\n",
    "            has_classes.append(pimage)\n",
    "            \n",
    "    for key in stats.keys():\n",
    "        stats[key] = stats[key] / pixel_sums\n",
    "        \n",
    "    return has_classes, stats\n",
    "        \n",
    "# im_list, stats = clear_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [4:46:18<00:00, 12.21s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "150 classes\n",
    "we need:\n",
    "1. sky (2)\n",
    "2. tree (4)\n",
    "3. grass (9)\n",
    "4. earth;ground (13)\n",
    "5. mountain;mount (16)\n",
    "6. plant;flora;plant;life (17)\n",
    "7. sea (27)\n",
    "8. \n",
    "\"\"\"\n",
    "\n",
    "def image_to_mask(images, model, feature_extractor) -> List[np.ndarray]:\n",
    "    inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    data: np.ndarray = np.array(logits.detach().numpy()).transpose((0, 2, 3, 1))\n",
    "    image_mask = np.argmax(data, axis=-1, keepdims=True)\n",
    "    return image_mask.astype(np.uint8)\n",
    "\n",
    "def read_images(paths):\n",
    "    return [io.imread(p) for p in paths]\n",
    "\n",
    "classes = parse_csv()\n",
    "\n",
    "files = glob('./data/lhq_256/images/*.png')\n",
    "batch = 64\n",
    "for i in tqdm(range(0, len(files), batch)):\n",
    "    paths = files[i:i+batch]\n",
    "    images = [io.imread(p) for p in paths]\n",
    "    masks = image_to_mask(images, model, feature_extractor)\n",
    "    for k in range(len(masks)):\n",
    "        mask = transform.resize(masks[k], images[k].shape, preserve_range=True).astype(np.uint8)\n",
    "        name = paths[k].replace('images', 'annotations')\n",
    "        io.imsave(name, mask, check_contrast=False)\n",
    "    \n",
    "    # print(np.unique(mask.flatten()))\n",
    "\n",
    "    # plt.axis('off')\n",
    "    # plt.imshow(np.hstack([mask, image]))\n",
    "    # plt.show()\n",
    "\n",
    "    # if i > 3: \n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def parse_csv(path: str = 'data/ADE20K/included_classes.csv', sep: str = ';'):\n",
    "    csv = pd.read_csv(path, sep=sep)\n",
    "    classes = {}\n",
    "    for index, (name, inc) in enumerate(zip(csv['Name'], csv['Include'])):\n",
    "        if inc:\n",
    "            classes[name] = index\n",
    "    return classes    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    classes = parse_csv()\n",
    "    transform_dataset(classes)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [3],\n",
       "        [2],\n",
       "        ...,\n",
       "        [2],\n",
       "        [1],\n",
       "        [0]],\n",
       "\n",
       "       [[4],\n",
       "        [3],\n",
       "        [1],\n",
       "        ...,\n",
       "        [4],\n",
       "        [2],\n",
       "        [3]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        ...,\n",
       "        [4],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0],\n",
       "        [4],\n",
       "        [0],\n",
       "        ...,\n",
       "        [2],\n",
       "        [2],\n",
       "        [1]],\n",
       "\n",
       "       [[2],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [4],\n",
       "        [2],\n",
       "        [0]],\n",
       "\n",
       "       [[3],\n",
       "        [2],\n",
       "        [0],\n",
       "        ...,\n",
       "        [3],\n",
       "        [2],\n",
       "        [1]]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.random((32, 32, 5))\n",
    "np.argmax(a, axis=-1, keepdims=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
